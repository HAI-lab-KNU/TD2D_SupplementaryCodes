{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c508e33-c12c-44f6-a775-91c3e94e0fdc",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d4f61-9e6b-4209-b01e-dd3bdc9762f2",
   "metadata": {},
   "source": [
    "## Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545f22dc-bd8a-4f95-b485-78c440ea0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH_DATA='./TD2D'\n",
    "sensor_data = ['PPG.csv', 'ECG.csv', 'EDA.csv', 'HR.csv', 'diameters.csv', 'fixations.csv', 'gazePositions.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5b8d2-9601-4f5b-b3ef-a6a398affe9a",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b082f9-d076-4df8-99bf-87534edba002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737f87c-9ec4-464c-a3b7-d35a8a805c06",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033e779-c990-42fa-bade-7d9cfbb6e5a1",
   "metadata": {},
   "source": [
    "## preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88db933e-73ef-44c6-97e1-85a6b75df6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.DataFrame()\n",
    "\n",
    "with os.scandir(PATH_DATA) as root:\n",
    "    for pid in root: #D1~D50\n",
    "        driver = os.path.basename(pid)[1:]\n",
    "\n",
    "        if driver.__contains__('idea'):\n",
    "            continue\n",
    "        elif driver.__contains__('xlsx'):\n",
    "            continue\n",
    "        elif driver.__contains__('DS_Store'):\n",
    "            continue\n",
    "\n",
    "        if os.path.isdir(pid):\n",
    "            with os.scandir(pid) as p:\n",
    "                label_driver = pd.DataFrame()\n",
    "                for task in p:  # e.g., audiobook listening\n",
    "                    if os.path.isdir(task):\n",
    "                        with os.scandir(task) as t:\n",
    "                            secondary_task = os.path.basename(task)\n",
    "                            #참조할 cases information csv file\n",
    "                            scenario_information = pd.read_csv(os.path.abspath(task)+'/takeoverScenarioInformations.csv', sep=',')\n",
    "                            #label\n",
    "                            label_task = pd.DataFrame([[driver, secondary_task]])\n",
    "                            label_task = pd.concat([label_task, scenario_information[['takeoverResult','reactionTime', 'NASA-TLX']]], axis=1, ignore_index=True)\n",
    "                            label_driver = pd.concat([label_driver, label_task], axis=0, ignore_index=True)\n",
    "                label = pd.concat([label, label_driver], axis=0, ignore_index=True)\n",
    "label.columns = ['driver', 'secondaryTask', 'takeoverResult', 'reactionTime', 'NASA_TLX']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c526648-18c0-4463-85fc-606c3eeef6e7",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a636f5f-d4a6-4286-b95f-a7eea43f7d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary Task                  Success Ratio (%)   Reaction Time (ms)        Perceived Workload\n",
      "                                                    Mean       SD             Mean     SD\n",
      "<Without secondary task>\n",
      "baseline                        86.0                880.98     201.80         29.60     22.99\n",
      "<Auditory tasks>\n",
      "0back                           82.0                883.06     235.94         33.37     21.18\n",
      "1back                           68.0                955.50     253.31         51.73     20.09\n",
      "2back                           72.0                978.62     209.32         66.91     16.44\n",
      "audiobook listening             76.0                905.26     213.36         38.28     18.95\n",
      "auditory texting                68.0                1016.90     264.46         45.81     20.92\n",
      "auditory gaming                 74.0                980.86     281.65         41.99     21.83\n",
      "<Visual tasks>\n",
      "ebook reading                   36.0                1294.30     483.59         71.25     15.06\n",
      "texting                         40.0                1352.58     433.19         60.47     18.71\n",
      "gaming                          38.0                1312.24     452.80         62.45     20.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define secondary task categories\n",
    "def categorize_task(task):\n",
    "    if task == 'baseline':\n",
    "        return '<Without secondary task>'\n",
    "    elif task in ['0back', '1back', '2back', 'audiobook listening', 'auditory gaming', 'auditory texting']:\n",
    "        return '<Auditory tasks>'\n",
    "    elif task in ['ebook reading', 'texting', 'gaming']:\n",
    "        return '<Visual tasks>'\n",
    "    return '<Unknown>'\n",
    "\n",
    "label['Category'] = label['secondaryTask'].apply(categorize_task)\n",
    "\n",
    "# Calculate success ratio\n",
    "success_ratios = label.groupby('secondaryTask').apply(lambda x: (x['takeoverResult'] == 'Success').mean() * 100)\n",
    "\n",
    "# Calculate means and standard deviations for reaction time and workload\n",
    "stats = label.groupby('secondaryTask').agg(\n",
    "    reactionTime_Mean=('reactionTime', 'mean'),\n",
    "    reactionTime_SD=('reactionTime', 'std'),\n",
    "    workload_Mean=('NASA_TLX', 'mean'),\n",
    "    workload_SD=('NASA_TLX', 'std')\n",
    ")\n",
    "\n",
    "# Merge success ratios\n",
    "stats = stats.join(success_ratios.rename('successRatio'))\n",
    "\n",
    "# Add category information to the grouped statistics\n",
    "stats = stats.reset_index().merge(label[['secondaryTask', 'Category']].drop_duplicates(), on='secondaryTask').set_index('secondaryTask')\n",
    "\n",
    "# Reorder columns\n",
    "stats = stats[['Category', 'successRatio', 'reactionTime_Mean', 'reactionTime_SD', 'workload_Mean', 'workload_SD']]\n",
    "\n",
    "# Set custom order for secondary tasks\n",
    "task_order = [\n",
    "    'baseline', '0back', '1back', '2back', 'audiobook listening',\n",
    "    'auditory texting', 'auditory gaming', 'ebook reading', 'texting', 'gaming'\n",
    "]\n",
    "stats.index = pd.CategoricalIndex(stats.index, categories=task_order, ordered=True)\n",
    "stats = stats.sort_index()\n",
    "\n",
    "# Define a function to format the output like the provided table\n",
    "def format_stats_table_with_headers(label):\n",
    "    table = \"Secondary Task                  Success Ratio (%)   Reaction Time (ms)        Perceived Workload\\n\"\n",
    "    table += \"                                                    Mean       SD             Mean     SD\\n\"\n",
    "    current_category = None\n",
    "    for index, row in label.iterrows():\n",
    "        if row['Category'] != current_category:\n",
    "            current_category = row['Category']\n",
    "            table += f\"{current_category}\\n\"\n",
    "        table += f\"{index:<30} {row['successRatio']:>5.1f}                {row['reactionTime_Mean']:>6.2f}     {row['reactionTime_SD']:>6.2f}        {row['workload_Mean']:>6.2f}    {row['workload_SD']:>6.2f}\\n\"\n",
    "    return table\n",
    "\n",
    "# Format the table and print it\n",
    "formatted_stats_table = format_stats_table_with_headers(stats)\n",
    "print(formatted_stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6118c170-8144-4718-9f37-d787a60a6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_info_df = pd.read_csv(PATH_DATA +'/driverInformation.csv')\n",
    "\n",
    "# add 'age_group' column\n",
    "driver_info_df['age_group'] = pd.cut(driver_info_df['age'], \n",
    "                                     bins=[19, 29, 39, 49, 59, 69], \n",
    "                                     labels=['20s', '30s', '40s', '50s', '60s'])\n",
    "\n",
    "# Create a DataFrame that includes age group information for drivers\n",
    "age_group_label = driver_info_df[['driverNumber', 'age_group']].copy()\n",
    "\n",
    "# convert data type of 'driver' & 'driverNumber' column\n",
    "label['driver'] = label['driver'].astype(int)\n",
    "age_group_label.loc[:, 'driverNumber'] = age_group_label['driverNumber'].astype(int)\n",
    "\n",
    "# add age_group colomn to 'label'\n",
    "label = label.merge(age_group_label, how='left', left_on='driver', right_on='driverNumber')\n",
    "label.drop(columns=['driverNumber'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ae761b-4aa7-403c-ab41-2c55b3df820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Age Group: 20s ===\n",
      "\n",
      "Secondary Task                  Success Ratio (%)   Reaction Time (ms)        Perceived Workload\n",
      "                                                    Mean       SD             Mean     SD\n",
      "<Without secondary task>\n",
      "baseline                        90.0                858.20     196.71         21.03     19.79\n",
      "<Auditory tasks>\n",
      "0back                          100.0                838.20     235.71         33.73     17.10\n",
      "1back                           80.0                865.40     178.93         55.73     20.26\n",
      "2back                           90.0                1036.40     269.77         69.07     15.23\n",
      "audiobook listening             70.0                882.80     170.69         43.63     14.51\n",
      "auditory texting                90.0                1003.20     155.20         49.37     20.32\n",
      "auditory gaming                 80.0                926.50     213.42         53.73     17.77\n",
      "<Visual tasks>\n",
      "ebook reading                   40.0                1399.30     469.20         72.73     12.90\n",
      "texting                         40.0                1325.80     367.41         53.50     21.23\n",
      "gaming                          60.0                1191.00     444.00         65.07     21.50\n",
      "\n",
      "\n",
      "=== Age Group: 30s ===\n",
      "\n",
      "Secondary Task                  Success Ratio (%)   Reaction Time (ms)        Perceived Workload\n",
      "                                                    Mean       SD             Mean     SD\n",
      "<Without secondary task>\n",
      "baseline                        90.0                1002.00     222.45         25.63     20.35\n",
      "<Auditory tasks>\n",
      "0back                           70.0                856.80     271.92         28.60     19.70\n",
      "1back                           90.0                847.70     282.04         47.93     18.37\n",
      "2back                           80.0                855.90     154.81         61.33      7.61\n",
      "audiobook listening             90.0                980.30     252.84         37.93     19.46\n",
      "auditory texting                90.0                1001.60     224.88         39.17     13.20\n",
      "auditory gaming                 80.0                974.90     335.53         33.70     19.23\n",
      "<Visual tasks>\n",
      "ebook reading                   40.0                1386.60     512.32         70.50     12.84\n",
      "texting                         70.0                1107.00     407.80         61.43     14.87\n",
      "gaming                          30.0                1200.90     345.63         56.20     22.63\n",
      "\n",
      "\n",
      "=== Age Group: 40s ===\n",
      "\n",
      "Secondary Task                  Success Ratio (%)   Reaction Time (ms)        Perceived Workload\n",
      "                                                    Mean       SD             Mean     SD\n",
      "<Without secondary task>\n",
      "baseline                        80.0                847.60     204.70         28.80     20.89\n",
      "<Auditory tasks>\n",
      "0back                           80.0                847.90     286.26         36.07     26.26\n",
      "1back                           80.0                1024.30     373.71         47.40     25.20\n",
      "2back                           60.0                1028.70     161.36         76.57     15.11\n",
      "audiobook listening            100.0                804.50     163.23         36.77     25.10\n",
      "auditory texting                60.0                980.20     327.27         53.17     22.36\n",
      "auditory gaming                 80.0                825.30     137.75         38.40     24.68\n",
      "<Visual tasks>\n",
      "ebook reading                   30.0                1196.10     541.75         73.37     18.04\n",
      "texting                         50.0                1304.80     515.97         56.50     16.63\n",
      "gaming                          70.0                1076.30     412.82         63.17     19.50\n",
      "\n",
      "\n",
      "=== Age Group: 50s ===\n",
      "\n",
      "Secondary Task                  Success Ratio (%)   Reaction Time (ms)        Perceived Workload\n",
      "                                                    Mean       SD             Mean     SD\n",
      "<Without secondary task>\n",
      "baseline                        80.0                873.60     199.57         32.03     29.30\n",
      "<Auditory tasks>\n",
      "0back                           80.0                877.10     186.47         31.67     26.75\n",
      "1back                           70.0                1009.70     163.19         46.57     18.54\n",
      "2back                           90.0                897.60     127.91         66.57     23.97\n",
      "audiobook listening             70.0                881.70     229.75         37.47     22.88\n",
      "auditory texting                70.0                993.20     196.41         41.40     24.60\n",
      "auditory gaming                 70.0                1079.30     306.93         36.17     24.97\n",
      "<Visual tasks>\n",
      "ebook reading                   60.0                1101.50     439.85         72.60     17.32\n",
      "texting                         20.0                1507.90     400.58         65.50     19.21\n",
      "gaming                          30.0                1378.90     409.30         68.47     19.21\n",
      "\n",
      "\n",
      "=== Age Group: 60s ===\n",
      "\n",
      "Secondary Task                  Success Ratio (%)   Reaction Time (ms)        Perceived Workload\n",
      "                                                    Mean       SD             Mean     SD\n",
      "<Without secondary task>\n",
      "baseline                        90.0                823.50     173.14         40.50     23.21\n",
      "<Auditory tasks>\n",
      "0back                           80.0                995.30     196.08         36.77     17.55\n",
      "1back                           20.0                1030.40     186.58         61.00     17.05\n",
      "2back                           40.0                1074.50     242.24         61.00     14.04\n",
      "audiobook listening             50.0                977.00     225.67         35.60     13.03\n",
      "auditory texting                30.0                1106.30     385.98         45.97     23.37\n",
      "auditory gaming                 60.0                1098.30     322.92         47.93     18.85\n",
      "<Visual tasks>\n",
      "ebook reading                   10.0                1388.00     469.24         67.03     15.77\n",
      "texting                         20.0                1517.40     407.84         65.40     21.45\n",
      "gaming                           0.0                1714.10     430.56         59.37     21.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouped statistics will be stored for each age group\n",
    "grouped_stats = {}\n",
    "\n",
    "# Loop through each age group and create sub_label for each group\n",
    "for age_group, group_data in label.groupby('age_group'):\n",
    "    # sub_label create\n",
    "    sub_label = group_data.copy()\n",
    "\n",
    "    # Calculate success ratio\n",
    "    success_ratios = sub_label.groupby('secondaryTask').apply(lambda x: (x['takeoverResult'] == 'Success').mean() * 100)\n",
    "\n",
    "    # Calculate means and standard deviations for reaction time and workload\n",
    "    stats = sub_label.groupby('secondaryTask').agg(\n",
    "        reactionTime_Mean=('reactionTime', 'mean'),\n",
    "        reactionTime_SD=('reactionTime', 'std'),\n",
    "        workload_Mean=('NASA_TLX', 'mean'),\n",
    "        workload_SD=('NASA_TLX', 'std')\n",
    "    )\n",
    "\n",
    "    # Merge success ratios\n",
    "    stats = stats.join(success_ratios.rename('successRatio'))\n",
    "\n",
    "    # Add category information to the grouped statistics\n",
    "    stats = stats.reset_index().merge(sub_label[['secondaryTask', 'Category']].drop_duplicates(), on='secondaryTask').set_index('secondaryTask')\n",
    "\n",
    "    # Reorder columns\n",
    "    stats = stats[['Category', 'successRatio', 'reactionTime_Mean', 'reactionTime_SD', 'workload_Mean', 'workload_SD']]\n",
    "\n",
    "    # Set custom order for secondary tasks\n",
    "    task_order = [\n",
    "        'baseline', '0back', '1back', '2back', 'audiobook listening',\n",
    "        'auditory texting', 'auditory gaming', 'ebook reading', 'texting', 'gaming'\n",
    "    ]\n",
    "    stats.index = pd.CategoricalIndex(stats.index, categories=task_order, ordered=True)\n",
    "    stats = stats.sort_index()\n",
    "\n",
    "    # Save the formatted stats table for the current age group\n",
    "    grouped_stats[age_group] = format_stats_table_with_headers(stats)\n",
    "\n",
    "# Print the formatted statistics table for each age group\n",
    "for age_group, table in grouped_stats.items():\n",
    "    print(f\"\\n=== Age Group: {age_group} ===\\n\")\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843bfa98-9b38-454a-9f29-5fe2ec88cb3a",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "547ca954-34f4-46d1-b3cd-3f164afe5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract(data: pd.DataFrame): # return features as a dataframe\n",
    "    features = pd.DataFrame([[data.min(), data.max(), data.mean(), data.skew(), data.kurtosis()]])\n",
    "    return features\n",
    "FEATURE_NUMBER = 5 # min, max, mean, skewness, kurtosis\n",
    "VALUE_NUMBER = 13 # sum of values\n",
    "DATA_DURATION = 10000 # 10 s\n",
    "\n",
    "feature = pd.DataFrame()\n",
    "label = pd.DataFrame()\n",
    "\n",
    "with os.scandir(PATH_DATA) as root:\n",
    "    for pid in root: #D1~D50\n",
    "        driver = os.path.basename(pid)[1:]\n",
    "\n",
    "        if driver.__contains__('idea'):\n",
    "            continue\n",
    "        elif driver.__contains__('xlsx'):\n",
    "            continue\n",
    "        elif driver.__contains__('DS_Store'):\n",
    "            continue\n",
    "\n",
    "        if os.path.isdir(pid):\n",
    "            with os.scandir(pid) as p:\n",
    "                feature_driver = pd.DataFrame()\n",
    "                label_driver = pd.DataFrame()\n",
    "                for task in p:  # 01_task_name\n",
    "                    if os.path.isdir(task):\n",
    "                        with os.scandir(task) as t:\n",
    "                            # takeoverScenarioMeasurements csv file\n",
    "                            takeoverScenarioMeasurements = pd.read_csv(os.path.abspath(task)+'/takeoverScenarioInformations.csv', sep=',')\n",
    "                            critical_event_occurrence_time = takeoverScenarioMeasurements.criticalEventOccurrenceTime.values[0]\n",
    "\n",
    "                            # Dataframe for feature extract\n",
    "                            feature_task = pd.DataFrame([driver], columns=['driver'])\n",
    "\n",
    "                            # Label\n",
    "                            label_task = pd.DataFrame([driver], columns=['driver'])\n",
    "                            label_task = pd.concat([label_task, takeoverScenarioMeasurements[['takeoverResult', 'reactionTime', 'NASA-TLX']]], axis=1, ignore_index=True)\n",
    "\n",
    "                            csvs = ['fixations', 'gazePositions', 'diameters', 'HR', 'PPG', 'ECG', 'EDA']\n",
    "                            for csv in t:   # e.g., ECG.csv\n",
    "                                f = os.path.basename(csv)\n",
    "                                if sensor_data.__contains__(f):\n",
    "                                    file = pd.read_csv(csv, sep=',')\n",
    "                                    \n",
    "                                    #selecting 10 seconds before critical event occurrence \n",
    "                                    idx_not_selected = file[(file['timestamp'] < (float(critical_event_occurrence_time) - DATA_DURATION)) | (file['timestamp'] > float(critical_event_occurrence_time))].index\n",
    "                                    file = file.drop(idx_not_selected)\n",
    "\n",
    "                                    if file.empty:\n",
    "                                        continue\n",
    "\n",
    "                                    # get feature\n",
    "                                    if f == 'fixations.csv':\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 1])], axis=1, ignore_index=True)\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 2])], axis=1, ignore_index=True)\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 3])], axis=1, ignore_index=True)\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 4])], axis=1, ignore_index=True)\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 5])], axis=1, ignore_index=True)\n",
    "                                    elif f == 'gazePositions.csv':\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 1])], axis=1, ignore_index=True)\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 2])], axis=1, ignore_index=True)\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 3])], axis=1, ignore_index=True)\n",
    "                                    elif f == 'diameters.csv':\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 1])], axis=1, ignore_index=True)\n",
    "                                    elif f == 'HR.csv':\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 1])], axis=1, ignore_index=True)\n",
    "                                    elif f == 'PPG.csv':\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 1])], axis=1, ignore_index=True)\n",
    "                                    elif f == 'ECG.csv':\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 1])], axis=1, ignore_index=True)\n",
    "                                    elif f == 'EDA.csv':\n",
    "                                        feature_task = pd.concat([feature_task, _extract(file.iloc[:, 1])], axis=1, ignore_index=True)\n",
    "                            feature_driver = pd.concat([feature_driver, feature_task], axis=0, ignore_index=True)\n",
    "                            label_driver = pd.concat([label_driver, label_task], axis=0, ignore_index=True)\n",
    "                # if remove this if condition, data will contain nan value and make 50 participants features.\n",
    "                if (not feature_driver.isna().values.any()) & (len(feature_driver.columns) == 1+VALUE_NUMBER*FEATURE_NUMBER):\n",
    "                    feature = pd.concat([feature, feature_driver], axis=0, ignore_index=True)\n",
    "                    label = pd.concat([label, label_driver], axis=0, ignore_index=True)\n",
    "label.columns = ['driver', 'takeoverResult', 'reactionTime', 'NASA-TLX']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415380e5-b0cf-4c1e-a128-d9afc1c9d0db",
   "metadata": {},
   "source": [
    "# Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34579d9f-3361-4dfe-a408-a7ef08f23ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "MAX_DEPTH = None\n",
    "\n",
    "ESTIMATOR_DUMMY_CLF = DummyClassifier(strategy='most_frequent')\n",
    "ESTIMATOR_RF_CLF = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "ESTIMATOR_XGB_CLF = XGBClassifier(random_state=RANDOM_STATE)\n",
    "ESTIMATOR_LGBM_CLF = LGBMClassifier(random_state=RANDOM_STATE, verbose=-1, importance_type='gain')\n",
    "ESTIMATOR_SVM_CLF = SVC(kernel='linear', random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2898ab4a-ac43-414c-9fda-583657f357d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(feature.iloc[:, 1:])\n",
    "y_tr = np.array(label.iloc[:, [1]]).ravel()\n",
    "y_tr = np.where(y_tr == \"Success\", 1, 0)\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "groups = np.array(feature.iloc[:,[0]]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e71772b-88c2-4f83-9c1b-f364ae6b917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "N_FEATURES = 20\n",
    "\n",
    "RF_accuracies = []\n",
    "RF_f1_scores_0 = []\n",
    "RF_f1_scores_1 = []\n",
    "RF_f1_scores_macro = []\n",
    "XGB_accuracies = []\n",
    "XGB_f1_scores_0 = []\n",
    "XGB_f1_scores_1 = []\n",
    "XGB_f1_scores_macro = []\n",
    "LGBM_accuracies = []\n",
    "LGBM_f1_scores_0 = []\n",
    "LGBM_f1_scores_1 = []\n",
    "LGBM_f1_scores_macro = []\n",
    "MLP_accuracies = []\n",
    "MLP_f1_scores_0 = []\n",
    "MLP_f1_scores_1 = []\n",
    "MLP_f1_scores_macro = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65cdf2-847a-44cc-9ae7-c7f6048324bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier\n",
    "for train_idx, test_idx in logo.split(X, y_tr, groups):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_clf_train, y_clf_test = y_tr[train_idx], y_tr[test_idx]\n",
    "    \n",
    "    # oversample\n",
    "    X_train, y_clf_train = sm.fit_resample(X_train, y_clf_train)\n",
    "\n",
    "    # Recursive Feature Elimination and model building\n",
    "    models = {\n",
    "        'RF': ESTIMATOR_RF_CLF,\n",
    "        'XGB': ESTIMATOR_XGB_CLF,\n",
    "        'LGBM': ESTIMATOR_LGBM_CLF,\n",
    "        'MLP': MLPClassifier(hidden_layer_sizes=(100, 30), max_iter=1000, random_state=RANDOM_STATE)#, learning_rate_init = 0.0005)\n",
    "    }\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        if model_name == 'MLP':\n",
    "            # Directly fit the MLP model without RFE\n",
    "            model.fit(X_train, y_clf_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "            accuracy = model.score(X_test, y_clf_test)\n",
    "        else:\n",
    "            # Use RFE for other models\n",
    "            selector = RFE(model, n_features_to_select=N_FEATURES, step=5)\n",
    "            selector = selector.fit(X_train, y_clf_train)\n",
    "            y_pred = selector.predict(X_test)\n",
    "            y_prob = selector.predict_proba(X_test)[:, 1]\n",
    "            accuracy = selector.score(X_test, y_clf_test)\n",
    "            \n",
    "        f1_score_0 = f1_score(y_clf_test, y_pred, average='binary', pos_label=0)\n",
    "        f1_score_1 = f1_score(y_clf_test, y_pred, average='binary', pos_label=1)\n",
    "        f1_score_macro = f1_score(y_clf_test, y_pred, average='macro')\n",
    "\n",
    "        if model_name == 'RF':\n",
    "            RF_accuracies.append(accuracy)\n",
    "            RF_f1_scores_0.append(f1_score_0)\n",
    "            RF_f1_scores_1.append(f1_score_1)\n",
    "            RF_f1_scores_macro.append(f1_score_macro)\n",
    "        elif model_name == 'XGB':\n",
    "            XGB_accuracies.append(accuracy)\n",
    "            XGB_f1_scores_0.append(f1_score_0)\n",
    "            XGB_f1_scores_1.append(f1_score_1)\n",
    "            XGB_f1_scores_macro.append(f1_score_macro)\n",
    "        elif model_name == 'LGBM':\n",
    "            LGBM_accuracies.append(accuracy)\n",
    "            LGBM_f1_scores_0.append(f1_score_0)\n",
    "            LGBM_f1_scores_1.append(f1_score_1)\n",
    "            LGBM_f1_scores_macro.append(f1_score_macro)\n",
    "        elif model_name == 'MLP':\n",
    "            MLP_accuracies.append(accuracy)\n",
    "            MLP_f1_scores_0.append(f1_score_0)\n",
    "            MLP_f1_scores_1.append(f1_score_1)\n",
    "            MLP_f1_scores_macro.append(f1_score_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18a530ec-ae4c-48c5-96a6-9c20424d64f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model              | F1 (Fail) (SD)| F1 (Success) (SD) | Avg. F1 (SD)  | Avg. Accuracy (SD)\n",
      "-------------------|---------------|-------------------|---------------|--------------\n",
      "Random Forest      | 0.441 (0.293) | 0.717 (0.174)     | 0.592 (0.176) | 0.677 (0.158)\n",
      "XGBoost            | 0.377 (0.271) | 0.674 (0.198)     | 0.526 (0.150) | 0.631 (0.142)\n",
      "LightGBM           | 0.361 (0.329) | 0.699 (0.241)     | 0.543 (0.200) | 0.669 (0.174)\n",
      "MLP                | 0.298 (0.303) | 0.647 (0.258)     | 0.472 (0.156) | 0.626 (0.192)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate averages and standard deviations for all models\n",
    "def calculate_stats(accuracies, f1_scores_0, f1_scores_1, f1_scores_macro):\n",
    "    return {\n",
    "        'avg_accuracy': np.mean(accuracies),\n",
    "        'std_accuracy': np.std(accuracies),\n",
    "        'avg_f1_score_0': np.mean(f1_scores_0),\n",
    "        'std_f1_0': np.std(f1_scores_0),\n",
    "        'avg_f1_score_1': np.mean(f1_scores_1),\n",
    "        'std_f1_1': np.std(f1_scores_1),\n",
    "        'avg_f1_score_macro': np.mean(f1_scores_macro),\n",
    "        'std_f1_macro': np.std(f1_scores_macro)\n",
    "    }\n",
    "\n",
    "RF_stats = calculate_stats(RF_accuracies, RF_f1_scores_0, RF_f1_scores_1, RF_f1_scores_macro)\n",
    "XGB_stats = calculate_stats(XGB_accuracies, XGB_f1_scores_0, XGB_f1_scores_1, XGB_f1_scores_macro)\n",
    "LGBM_stats = calculate_stats(LGBM_accuracies, LGBM_f1_scores_0, LGBM_f1_scores_1, LGBM_f1_scores_macro)\n",
    "MLP_stats = calculate_stats(MLP_accuracies, MLP_f1_scores_0, MLP_f1_scores_1, MLP_f1_scores_macro)\n",
    "\n",
    "results = {\n",
    "    'Random Forest': RF_stats,\n",
    "    'XGBoost': XGB_stats,\n",
    "    'LightGBM': LGBM_stats,\n",
    "    'MLP': MLP_stats\n",
    "}\n",
    "\n",
    "# Function to format the results into a table\n",
    "def format_results_table(results):\n",
    "    header = (\n",
    "        \"Model              | F1 (Fail) (SD)| F1 (Success) (SD) | Avg. F1 (SD)  | Avg. Accuracy (SD)\\n\"\n",
    "        \"-------------------|---------------|-------------------|---------------|--------------\\n\"\n",
    "    )\n",
    "    rows = []\n",
    "    for model, stats in results.items():\n",
    "        row = (\n",
    "            f\"{model:<18} | \"\n",
    "            f\"{stats['avg_f1_score_0']:.3f} ({stats['std_f1_0']:.3f}) | \"\n",
    "            f\"{stats['avg_f1_score_1']:.3f} ({stats['std_f1_1']:.3f})     | \"\n",
    "            f\"{stats['avg_f1_score_macro']:.3f} ({stats['std_f1_macro']:.3f}) | \"\n",
    "            f\"{stats['avg_accuracy']:.3f} ({stats['std_accuracy']:.3f})\"\n",
    "        )\n",
    "        rows.append(row)\n",
    "    table = header + \"\\n\".join(rows)\n",
    "    return table\n",
    "\n",
    "# Print the formatted results table\n",
    "print(format_results_table(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b7338-f0ec-4141-8b4a-d36ac2f176de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
